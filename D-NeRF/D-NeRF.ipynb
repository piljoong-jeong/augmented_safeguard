{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# NOTE: material: https://drive.google.com/drive/u/0/folders/14J6oWZzULqtXfIv99064Cs0iHVdeat22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir_project='/root/Documents/Projects/augmented_safeguard/D-NeRF'\n",
      "os.getcwd()='/root/Documents/Projects/augmented_safeguard/D-NeRF'\n"
     ]
    }
   ],
   "source": [
    "# NOTE: access to directory\n",
    "dir_project = os.path.abspath(\".\")\n",
    "print(f\"{dir_project=}\")\n",
    "os.chdir(dir_project)\n",
    "print(f\"{os.getcwd()=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import imageio\n",
    "import lpips\n",
    "import numpy as np\n",
    "import torch\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import mcubes\n",
    "import trimesh\n",
    "from tqdm import tqdm, trange\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: extended `config_parser()`\n",
    "\n",
    "import NeRF.config_parser\n",
    "\n",
    "def config_parser():\n",
    "    import argparse\n",
    "    parser = NeRF.config_parser.config_parser()\n",
    "\n",
    "    # NOTE: D-NeRF training options\n",
    "    # ------------------------------------------\n",
    "    parser.add_argument(\"--nerf_type\", type=str, default=\"original\", help=\"nerf network type\")\n",
    "    parser.add_argument(\"--N_iter\", type=int, default=500000, help=\"num training iterations\")\n",
    "    parser.add_argument(\"--do_half_precision\", action=\"store_true\", help=\"do half precision training and inference\")\n",
    "\n",
    "    parser.add_argument(\"--add_tv_loss\", action=\"store_true\", help=\"evaluate tv loss\")\n",
    "    parser.add_argument(\"--tv_loss_weight\", type=float, default=1.e-4, help=\"weight of tv loss\")\n",
    "    # ------------------------------------------\n",
    "    \n",
    "    # NOTE: D-NeRF rendering options\n",
    "    # ------------------------------------------\n",
    "    parser.add_argument(\"--not_zero_canonical\", action=\"store_true\", help=\"if set zero time is not the canonic space\")\n",
    "    parser.add_argument(\"--use_two_models_for_fine\", action=\"store_true\", help=\"use two models for fine results\")\n",
    "    # ------------------------------------------\n",
    "\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'expname': 'mutant', 'basedir': './logs', 'datadir': './data/mutant', 'dataset_type': 'blender', 'nerf_type': 'direct_temporal', 'no_batching': 'True', 'not_zero_canonical': 'False', 'use_viewdirs': 'True', 'white_bkgd': 'True', 'lrate_decay': '500', 'N_iter': '800000', 'N_samples': '64', 'N_importance': '128', 'N_rand': '500', 'testskip': '1', 'precrop_iters': '500', 'precrop_iters_time': '100000', 'precrop_frac': '0.5', 'half_res': 'True', 'do_half_precision': 'False'}\n"
     ]
    }
   ],
   "source": [
    "# NOTE: parse arguments & load config\n",
    "parser = config_parser()\n",
    "filename_config = \"configs/mutant.txt\"\n",
    "configs = NeRF.config_parser.load_config(parser, filename_config)\n",
    "print(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(N_importance=128, N_iter=800000, N_rand=500, N_samples=64, add_tv_loss=False, basedir='./logs', chunk=32768, datadir='./data/mutant', dataset_type='blender', do_half_precision='False', expname='mutant', factor=8, ft_path=None, half_res='True', i_embed=0, i_img=500, i_print=100, i_testset=50000, i_video=50000, i_weights=10000, lindisp=False, llffhold=8, lrate=0.0005, lrate_decay=500, multires=10, multires_views=4, nerf_type='direct_temporal', netchunk=65536, netdepth=8, netdepth_fine=8, netwidth=256, netwidth_fine=256, no_batching='True', no_ndc=False, no_reload=True, not_zero_canonical='False', perturb=1.0, precrop_frac=0.5, precrop_iters=500, precrop_iters_time=100000, raw_noise_std=0.0, render_factor=0, render_only=False, render_test=False, shape='greek', spherify=False, testskip=1, tv_loss_weight=0.0001, use_two_models_for_fine=False, use_viewdirs='True', white_bkgd='True')\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# NOTE: assign configs to arguments\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "args.expname = configs['expname']\n",
    "args.basedir = configs['basedir']\n",
    "args.datadir = configs['datadir']\n",
    "args.dataset_type = configs['dataset_type']\n",
    "\n",
    "args.nerf_type = configs['nerf_type']\n",
    "args.no_batching = configs['no_batching']\n",
    "args.not_zero_canonical = configs['not_zero_canonical']\n",
    "\n",
    "args.use_viewdirs = configs['use_viewdirs']\n",
    "args.white_bkgd = configs['white_bkgd']\n",
    "args.lrate_decay = int(configs['lrate_decay'])\n",
    "\n",
    "args.N_iter = int(configs['N_iter'])\n",
    "args.N_samples = int(configs['N_samples'])\n",
    "args.N_importance = int(configs['N_importance'])\n",
    "args.N_rand = int(configs['N_rand'])\n",
    "args.testskip = int(configs['testskip'])\n",
    "\n",
    "args.precrop_iters = int(configs['precrop_iters'])\n",
    "args.precrop_iters_time = int(configs['precrop_iters_time'])\n",
    "args.precrop_frac = float(configs['precrop_frac'])\n",
    "\n",
    "args.half_res = configs['half_res']\n",
    "args.do_half_precision = configs['do_half_precision']\n",
    "\n",
    "args.no_reload = True # NOTE: for now set to True as we'll implement training code\n",
    "\n",
    "print(args)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "DEBUG=False\n",
    "print(device)\n",
    "\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "augmented_safeguard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
